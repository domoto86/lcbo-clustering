{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf9afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import requests\n",
    "import json\n",
    "from config import geoapify_key\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "browser = Browser('chrome')\n",
    "browser.driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea4667a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementDoesNotExist",
     "evalue": "no elements could be found with link by text \"English\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\splinter\\element_list.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mElementDoesNotExist\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4264\\538931355.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_by_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'English'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\splinter\\element_list.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\splinter\\element_list.py\u001b[0m in \u001b[0;36mfirst\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0melement_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0melement_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \"\"\"\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\splinter\\element_list.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             raise ElementDoesNotExist(\n\u001b[0m\u001b[0;32m     43\u001b[0m                 u'no elements could be found with {0} \"{1}\"'.format(\n\u001b[0;32m     44\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_by\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementDoesNotExist\u001b[0m: no elements could be found with link by text \"English\""
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the web page\n",
    "url = \"https://www.lcbo.com/en/products#t=clp-products&sort=relevancy&layout=card&f:@lcbo_current_offer=[On%20Sale]&f:@ec_category=[Wine]\"\n",
    "browser.visit(url)\n",
    "\n",
    "# To select \"English\" as preffered language\n",
    "time.sleep(3)\n",
    "results = browser.links.find_by_text('English')\n",
    "results.click()\n",
    "time.sleep(3)\n",
    "\n",
    "html = browser.html\n",
    "soup=BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92375b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes the cookie popup\n",
    "cookie = browser.find_by_id('btn-cookie-allow').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "while True:\n",
    "    try:     \n",
    "        # Wait for 1 second\n",
    "        time.sleep(2)\n",
    "        # Click on Load More button\n",
    "        browser.find_by_id('loadMore').click()\n",
    "    except:\n",
    "        break\n",
    "    print(iteration)\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "    \n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "all_links = soup.find_all(\"div\", class_ = 'coveo-product-items')\n",
    "\n",
    "links = []\n",
    "\n",
    "for link in all_links:\n",
    "    results = link.a['href']\n",
    "    links.append(results)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7f6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(links))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# div_element = soup.find('div', class_='fotorama__stage__frame')\n",
    "# if div_element and 'href' in div_element.attrs:\n",
    "#     link = div_element['href']\n",
    "#     print(link)\n",
    "# else:\n",
    "#     print(\"Link not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab256df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regular_price = []\n",
    "sale_price = []\n",
    "name = []\n",
    "rating = []\n",
    "onsale = [] #this is the On Sale tag\n",
    "reviews = []\n",
    "size = []\n",
    "description = []\n",
    "category = []\n",
    "details_list = []\n",
    "taste_list = []\n",
    "images = []\n",
    "\n",
    "\n",
    "max_iteration2 = len(links)\n",
    "iteration2 = 0\n",
    "\n",
    "\n",
    "for record in links:\n",
    "    if iteration2 >= max_iteration2:\n",
    "        break\n",
    "    url = record\n",
    "    browser.visit(url)\n",
    "    time.sleep(2)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "#     time.sleep(1)\n",
    "#     browser.find_by_css('my_store_close_button').click()\n",
    "\n",
    "    try:\n",
    "        div_element = soup.find('div', class_='fotorama__stage__frame')\n",
    "        if div_element and 'href' in div_element.attrs:\n",
    "            link = div_element['href']\n",
    "            images.append(link)\n",
    "        else:\n",
    "            print(\"Link not found.\")\n",
    "    except AttributeError:\n",
    "        images.append('N/A')\n",
    "        \n",
    "    try:\n",
    "        old_price = soup.find('span', class_ = 'old-price')\n",
    "        old = old_price.find('span', class_ = 'price')\n",
    "        regular_price.append(old.find('span', class_ = 'price').text)\n",
    "    except AttributeError:\n",
    "        regular_price.append('N/A')\n",
    "\n",
    "    try:\n",
    "        on_sale_price = soup.find('span', class_ = 'special-price')\n",
    "        new_price = on_sale_price.find('span', class_ = 'price')\n",
    "        sale_price.append(new_price.find('span', class_ = 'price').text)\n",
    "    except AttributeError:\n",
    "        sale_price.append('N/A')\n",
    "    \n",
    "    try:    \n",
    "        name.append(soup.find('div', class_ = 'page-title-wrapper').text)\n",
    "    except AttributeError:\n",
    "        name.append('N/A')\n",
    "        \n",
    "    try:\n",
    "        onsale.append(soup.find('div', class_ = 'amlabel-text').text)\n",
    "    except AttributeError:\n",
    "        onsale.append('N/A')\n",
    "    \n",
    "    try:\n",
    "        rating.append(soup.find('div', class_ = 'bv_avgRating_component_container notranslate').text)\n",
    "    except AttributeError:\n",
    "        rating.append('N/A')\n",
    "    \n",
    "    try:\n",
    "        reviews.append(soup.find('div', class_ = 'bv_numReviews_text').text)\n",
    "    except AttributeError:\n",
    "        reviews.append('N/A')\n",
    "    \n",
    "    try:\n",
    "        size.append(soup.find('div', class_ = 'lcbo-product-size').text)\n",
    "    except AttributeError:\n",
    "        size.append('N/A')\n",
    "        \n",
    "    try:\n",
    "        description.append(soup.find('div', class_ = 'testing_note').text)\n",
    "    except AttributeError:\n",
    "        description.append('N/A')\n",
    "        \n",
    "    categories_all = soup.find('div', class_ = 'breadcrumbs')\n",
    "    categories = categories_all.find_all('li', class_ = 'item')\n",
    "    category_list = []\n",
    "\n",
    "    for category_record in categories:\n",
    "        category_list.append(category_record.text)\n",
    "    category.append(category_list[-2])\n",
    "\n",
    "    moredetail = soup.find('div', class_ = 'moredetail')\n",
    "    all_details = moredetail.find_all('li')\n",
    "    details = {}\n",
    "\n",
    "    for detail_record in all_details:\n",
    "        details_value = detail_record.find('div', class_ = 'value').text\n",
    "        details_name = detail_record.find('div', class_ = 'label').text\n",
    "        details[details_name] = details_value\n",
    "\n",
    "    details_list.append(details)\n",
    "    \n",
    "#     try:\n",
    "#         flavour_all = soup.find('div', class_ = 'foodParings pip-info')\n",
    "#         flavour = flavour_all.find('div', class_ = 'label').text\n",
    "#         flavour_value = flavour_all.find('div', class_ = 'value').text\n",
    "#         flavours = {\n",
    "#             flavour: flavour_value\n",
    "#         }\n",
    "#     except AttributeError:\n",
    "#         flavours = {\n",
    "#             'Flavour': 'N/A'\n",
    "#         }\n",
    "        \n",
    "    \n",
    "#     try:\n",
    "#         all_taste = soup.find('div', class_ = 'foodParings pip-info')\n",
    "#         li_all = all_taste.find_all('li')\n",
    "\n",
    "#         for li in li_all:\n",
    "#             label = li.find('div', class_='label').text.strip()\n",
    "#             value_element = li.find('div', class_='value')\n",
    "#             if 'aria-label' in value_element.attrs:\n",
    "#                 aria_label = value_element['aria-label']\n",
    "#                 number = re.findall(r'\\d+', aria_label)\n",
    "#                 if number:\n",
    "#                     taste_list.append({\n",
    "#                         label: int(number[0])\n",
    "#                     })\n",
    "#     except AttributeError:\n",
    "#         taste_list.append('N/A')\n",
    "        \n",
    "    print(iteration2)\n",
    "    iteration2 += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930de2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Name': name,\n",
    "    'Regular Price': regular_price,\n",
    "    'Sale Price': sale_price,\n",
    "    'Rating': rating,\n",
    "    'Reviews': reviews,\n",
    "    'Size': size,\n",
    "    'Description': description,\n",
    "    'Category': category,\n",
    "    'Details': details_list,\n",
    "    'Image': images\n",
    "#     'Flavours': flavours\n",
    "    \n",
    "}\n",
    "\n",
    "# Add the details dictionary to the data dictionary\n",
    "data['Details'] = details_list\n",
    "# data['Taste'] = taste_list\n",
    "\n",
    "# Create a dataframe from the data dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "details_df = pd.json_normalize(df['Details'])\n",
    "# taste_df = pd.json_normalize(df['Taste'])\n",
    "\n",
    "df = pd.concat([df, details_df], axis = 1)\n",
    "# df2 = pd.concat([df1, taste_df], axis = 1)\n",
    "\n",
    "df.drop('Details', axis = 1, inplace = True)\n",
    "# df2.drop('Taste', axis = 1, inplace = True)\n",
    "\n",
    "#Adding Latitude and Longitude columns to the Data Frame\n",
    "df['Lat'] = \"\"\n",
    "df['Lon'] = \"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdaadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(regular_price))\n",
    "print(len(sale_price))\n",
    "print(len(name))\n",
    "print(len(rating))\n",
    "print(len(onsale))\n",
    "print(len(reviews))\n",
    "print(len(size))\n",
    "print(len(description))\n",
    "print(len(category))\n",
    "print(len(details_list))\n",
    "print(len(images))\n",
    "# print(len(flavours))\n",
    "# print(flavours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API call to get Latitude and Longitude\n",
    "params = {\n",
    "    \"apiKey\":geoapify_key,\n",
    "    \"format\":\"json\"\n",
    "}\n",
    "\n",
    "# Set the base URL\n",
    "base_url = \"https://api.geoapify.com/v1/geocode/search\"\n",
    "\n",
    "df['Lat'] = None\n",
    "df['Lon'] = None\n",
    "\n",
    "for index, country in df['Made In'].to_frame().iterrows():\n",
    "    location = country['Made In']\n",
    "    params[\"text\"] = location\n",
    "    \n",
    "    response = requests.get(base_url, params=params).json()\n",
    "\n",
    "    latitude = response[\"results\"][0][\"lat\"]\n",
    "    longitude = response[\"results\"][0][\"lon\"]\n",
    "    df.loc[index, \"Lat\"] = latitude\n",
    "    df.loc[index, \"Lon\"] = longitude\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Name'] == ' Allegrini Palazzo della Torre 2019', 'Regular Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Regular Price'] = df['Regular Price'].str.replace('$','')\n",
    "df['Sale Price'] = df['Sale Price'].str.replace('$','')\n",
    "\n",
    "\n",
    "df['Savings'] = df['Regular Price'].astype(float) - df['Sale Price'].astype(float)\n",
    "\n",
    "df['Alcohol/Vol'] = df['Alcohol/Vol'].str.rstrip('%')\n",
    "df['Alcohol/Vol'] = pd.to_numeric(df['Alcohol/Vol']) /100\n",
    "df['Image'] = df['Image'].str.replace('1280.1280','319.319')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Sugar Content' : 'Sugar Content g/L'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff703cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df = df.isna()\n",
    "df = df.fillna('N/A')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_lists = {column: df[column].tolist() if not np.issubdtype(df[column].dtype, np.number) else df[column].fillna('N/A').tolist() for column in df.columns}\n",
    "\n",
    "name_list = column_lists['Name']\n",
    "regular_price_list = column_lists['Regular Price']\n",
    "sale_price_list = column_lists['Sale Price']\n",
    "rating_list = column_lists['Rating']\n",
    "reviews_list = column_lists['Reviews']\n",
    "size_list = column_lists['Size']\n",
    "description_list = column_lists['Description']\n",
    "category_list = column_lists['Category']\n",
    "alcohol_list = column_lists['Alcohol/Vol']\n",
    "madein_list = column_lists['Made In']\n",
    "by_list = column_lists['By']\n",
    "varietal_list = column_lists['Varietal']\n",
    "lat_list = column_lists['Lat']\n",
    "lon_list = column_lists['Lon']\n",
    "savings_list = column_lists['Savings']\n",
    "images_list = column_lists['Image']\n",
    "\n",
    "lcbo_1 = {\n",
    "    'name': name_list,\n",
    "    'regular_price': regular_price_list,\n",
    "    'sale_price': sale_price_list,\n",
    "    'rating': rating_list,\n",
    "    'reviews': reviews_list,\n",
    "    'size': size_list,\n",
    "    'description': description_list,\n",
    "    'category': category_list,\n",
    "    'alcohol_vol': alcohol_list,\n",
    "    'made_in': madein_list,\n",
    "    'by': by_list,\n",
    "    'varietal': varietal_list,\n",
    "    'lat': lat_list,\n",
    "    'lon': lon_list,\n",
    "    'savings': savings_list,\n",
    "    'image': images_list\n",
    "}\n",
    "\n",
    "with open('lcbo_1.json', 'w') as file:\n",
    "    json.dump(lcbo_1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94953c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_lists = {column: df[column].tolist() if not np.issubdtype(df[column].dtype, np.number) else df[column].fillna('N/A').tolist() for column in df.columns}\n",
    "\n",
    "name_list = column_lists['Name']\n",
    "regular_price_list = column_lists['Regular Price']\n",
    "sale_price_list = column_lists['Sale Price']\n",
    "rating_list = column_lists['Rating']\n",
    "reviews_list = column_lists['Reviews']\n",
    "size_list = column_lists['Size']\n",
    "description_list = column_lists['Description']\n",
    "category_list = column_lists['Category']\n",
    "alcohol_list = column_lists['Alcohol/Vol']\n",
    "madein_list = column_lists['Made In']\n",
    "by_list = column_lists['By']\n",
    "varietal_list = column_lists['Varietal']\n",
    "lat_list = column_lists['Lat']\n",
    "lon_list = column_lists['Lon']\n",
    "savings_list = column_lists['Savings']\n",
    "images_list = column_lists['Image']\n",
    "\n",
    "lcbo_2 = {\n",
    "    'name': name_list,\n",
    "    'regular_price': regular_price_list,\n",
    "    'sale_price': sale_price_list,\n",
    "    'rating': rating_list,\n",
    "    'reviews': reviews_list,\n",
    "    'size': size_list,\n",
    "    'description': description_list,\n",
    "    'category': category_list,\n",
    "    'alcohol_vol': alcohol_list,\n",
    "    'made_in': madein_list,\n",
    "    'by': by_list,\n",
    "    'varietal': varietal_list,\n",
    "    'lat': lat_list,\n",
    "    'lon': lon_list,\n",
    "    'savings': savings_list,\n",
    "    'image': images_list\n",
    "}\n",
    "\n",
    "with open('lcbo_2.json', 'w') as file:\n",
    "    file.write(pd.DataFrame(lcbo_2).to_json(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a343532",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lcbo_1.json', 'r') as file1:\n",
    "    lcbo1 = json.load(file1)\n",
    "\n",
    "# Read the contents of the second JSON file\n",
    "with open('lcbo_2.json', 'r') as file2:\n",
    "    lcbo2 = json.load(file2)\n",
    "\n",
    "# Merge the two JSON data\n",
    "\n",
    "merged_data = lcbo2\n",
    "merged_data.extend(lcbo1)\n",
    "\n",
    "# Write the merged data to a new JSON file\n",
    "with open('lcbo_merged.json', 'w') as outfile:\n",
    "    json.dump(merged_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lcbo_wines.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bba4bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
